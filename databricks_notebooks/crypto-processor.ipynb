{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a26e912-e66b-48c7-a325-b2477df19673",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDD04 Processing data for: 2025-06-07\n\uD83D\uDCC2 Reading from: wasbs://crypto-data@[REDACTED].blob.core.windows.net/raw/2025-06-07/*.json\n✅ Saved sorted data to: wasbs://crypto-data@[REDACTED].blob.core.windows.net/processed/2025-06-07.parquet\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import from_unixtime, col, date_format\n",
    "from datetime import datetime\n",
    "\n",
    "# ── 1. Initialize Spark session ────────────────────────────────────────────────\n",
    "spark = SparkSession.builder.appName(\"CryptoProcessorToday\").getOrCreate()\n",
    "\n",
    "# ── 2. Secret-based credentials ────────────────────────────────────────────────\n",
    "storage_account_name = dbutils.secrets.get(scope=\"cryptoSecret\", key=\"azure-storage-account-name\")\n",
    "storage_account_key  = dbutils.secrets.get(scope=\"cryptoSecret\", key=\"azure-storage-account-key\")\n",
    "container_name       = \"crypto-data\"\n",
    "\n",
    "# Configure Spark for Azure Blob Storage\n",
    "spark.conf.set(f\"fs.azure.account.key.{storage_account_name}.blob.core.windows.net\", storage_account_key)\n",
    "\n",
    "# ── 3. Define today's date and paths ────────────────────────────────────────────\n",
    "today_str = datetime.today().strftime(\"%Y-%m-%d\")  # e.g., '2025-06-07'\n",
    "\n",
    "raw_base_path       = f\"wasbs://{container_name}@{storage_account_name}.blob.core.windows.net/raw\"\n",
    "processed_base_path = f\"wasbs://{container_name}@{storage_account_name}.blob.core.windows.net/processed\"\n",
    "\n",
    "json_files_path = f\"{raw_base_path}/{today_str}/*.json\"\n",
    "output_path     = f\"{processed_base_path}/{today_str}.parquet\"\n",
    "\n",
    "print(f\"\uD83D\uDD04 Processing data for: {today_str}\")\n",
    "print(f\"\uD83D\uDCC2 Reading from: {json_files_path}\")\n",
    "\n",
    "# ── 4. Read, transform, and write today's data ─────────────────────────────────\n",
    "try:\n",
    "    df = spark.read.json(json_files_path)\n",
    "\n",
    "    if df.count() == 0:\n",
    "        print(f\"⚠️ No data found for today at: {json_files_path}\")\n",
    "    else:\n",
    "        df_inr = (\n",
    "            df.select(\n",
    "                from_unixtime(col(\"timestamp\")).alias(\"timestamp_readable\"),\n",
    "                col(\"prices.bitcoin.inr\").alias(\"bitcoin\"),\n",
    "                col(\"prices.ethereum.inr\").alias(\"ethereum\"),\n",
    "                col(\"prices.dogecoin.inr\").alias(\"dogecoin\")\n",
    "            )\n",
    "            .withColumn(\"date\", date_format(col(\"timestamp_readable\"), \"yyyy-MM-dd\"))\n",
    "            .withColumn(\"time\", date_format(col(\"timestamp_readable\"), \"HH:mm:ss\"))\n",
    "            .select(\"date\", \"time\", \"bitcoin\", \"ethereum\", \"dogecoin\")\n",
    "            .orderBy(col(\"time\").asc())  # sort by time\n",
    "        )\n",
    "\n",
    "        df_inr.write.mode(\"overwrite\").parquet(output_path)\n",
    "        print(f\"✅ Saved sorted data to: {output_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Failed to process {json_files_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "49687689-399a-4c5c-98b2-18b4e17e47f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "crypto-processor",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}